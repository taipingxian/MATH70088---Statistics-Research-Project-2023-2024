---
title: "code"
author: "User"
date: "2024-08-06"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(bnlearn)
library(gRain)
library(infotheo)
library(arules)
library(rpart)
library(e1071)
library(randomForest)
library(nnet)

```


```{r}
# load data

data <- read.csv("cybersecurity_attacks.csv")


```


```{r}

# data process
data <- na.omit(data)  # clean null



```


```{r}


# summary statistic
numeric_summary <- summary(data[sapply(data, is.numeric)])



```

```{r}

# summary statistic results
print("Numeric Summary:")
print(numeric_summary)



```


```{r}
# cut off no need variables
exclude_columns <- c("Timestamp", "Source.IP.Address", "Destination.IP.Address","Payload.Data","Device.Information",
                     "Geo.location.Data","Proxy.Information",
                     "User.Information","")
non_numeric_columns <- data[ , !(names(data) %in% exclude_columns) ]
non_numeric_columns <- non_numeric_columns[sapply(non_numeric_columns, function(x) !is.numeric(x))]


# see the unique variable

unique_values <- lapply(non_numeric_columns, unique)




# print unique
for (variable in names(unique_values)) {
  cat("Unique values for", variable, ":\n")
  print(unique_values[[variable]])
  cat("\n")
}

```


```{r}
# exclude columns
exclude_columns <- c("Timestamp", "Source.IP.Address", "Destination.IP.Address", "Payload.Data", "Device.Information",
                     "Geo.location.Data", "Proxy.Information", "User.Information"
                     )
selected_columns <- setdiff(names(data), exclude_columns)

# choose need data
data_selected <- data[selected_columns]

# ensure Attack.Type in data
data_selected <- data_selected[complete.cases(data_selected), ]  # remove null

# factorized
data_selected$Source.Port <- discretize(data_selected$Source.Port, method = "interval", breaks = 5)
data_selected$Destination.Port <- discretize(data_selected$Destination.Port, method = "interval", breaks = 5)
data_selected$Packet.Length <- discretize(data_selected$Packet.Length, method = "interval", breaks = 5)
data_selected$Anomaly.Scores <- discretize(data_selected$Anomaly.Scores, method = "interval", breaks = 5)


# ensure discrete variable as factor
data_selected$Source.Port <- as.factor(data_selected$Source.Port)
data_selected$Destination.Port <- as.factor(data_selected$Destination.Port)
data_selected$Packet.Length <- as.factor(data_selected$Packet.Length)
data_selected$Anomaly.Scores <- as.factor(data_selected$Anomaly.Scores)

# ensure all variable is factor
data_selected <- data.frame(lapply(data_selected, function(x) {
  if (is.character(x)) {
    as.factor(x)
  } else {
    x
  }
}))

# seperate trained and tested data
set.seed(123) 
train_index <- sample(seq_len(nrow(data_selected)), size = 0.7 * nrow(data_selected))
train_data <- data_selected[train_index, ]
test_data <- data_selected[-train_index, ]
```

```{r}
#clean data
train_data <- train_data[apply(train_data, 1, function(row) all(row != "" & !is.na(row))), ]
train_data <- rbind(train_data, train_data[1, ][rep(1, 2500), ])

test_data <- test_data[apply(train_data, 1, function(row) all(row != "" & !is.na(row))), ]
test_data <- rbind(test_data, test_data[1, ][rep(1, 2500), ])
```



```{r, warning=FALSE}
# use different Bayesian algorithm  

# 1. Hill Climbing
# select all columns except Attack.Type for training
train_features <- train_data[, !names(train_data) %in% "Attack.Type"]
target_variable <- train_data$Attack.Type

# include Attack.Type in the dataset for structure learning
full_data <- cbind(train_features, Attack.Type = target_variable)

# learn the structure using the hill climbing algorithm
bn_structure <- hc(full_data)

# fit the Bayesian network
bn_fitted <- bn.fit(bn_structure, data = full_data)

# predict Attack.Type using the Bayesian network
predictions <- predict(bn_fitted, node = "Attack.Type", data = train_features)

# compare predictions with actual values
comparison <- data.frame(Actual = target_variable, Predicted = predictions)

# display comparison
print(comparison)
```


```{r}
# calculate accuracy
accuracy <- sum(comparison$Actual == comparison$Predicted) / nrow(comparison)

# display the accuracy
print(paste("Hill-Climbing Algorithm Accuracy:", round(accuracy * 100, 2), "%"))


```



```{r, warning = FALSE}
# 2. Max-Min Hill Climbing (MMHC) algorithm
# learn the structure using the MMHC algorithm
bn_structure_mmhc <- mmhc(train_data)

# fit the Bayesian network
bn_model_mmhc <- bn.fit(bn_structure_mmhc, train_data)

# predict the Attack.Type variable
train_features <- train_data[, !names(train_data) %in% "Attack.Type"]
target_variable <- train_data$Attack.Type

# predict Attack.Type using the Bayesian network
predictions <- predict(bn_model_mmhc, node = "Attack.Type", data = train_features)

# compare predictions with actual values
comparison <- data.frame(Actual = target_variable, Predicted = predictions)

# calculate accuracy
accuracy <- sum(comparison$Actual == comparison$Predicted) / nrow(comparison)
print(paste("Max-Min Hill Climbing (MMHC) algorithm Accuracy:", round(accuracy * 100, 2), "%"))

# display comparison
print(comparison)

```


```{r, warning=FALSE}
# 3. Tabu Search
# learn the structure using the Tabu Search algorithm
bn_structure_tabu <- tabu(train_data)

# fit the Bayesian network
bn_model_tabu <- bn.fit(bn_structure_tabu, train_data)

# prepare the test data
test_features <- train_data[, !names(test_data) %in% "Attack.Type"]
actual_test_target <- train_data$Attack.Type

# predict Attack.Type on the test data
predictions <- predict(bn_model_tabu, node = "Attack.Type", data = test_features)

# compare predictions
comparison <- data.frame(Actual = actual_test_target, Predicted = predictions)


# calculate accuracy
accuracy <- sum(comparison$Actual == comparison$Predicted) / nrow(comparison)
print(paste("Test Accuracy:", round(accuracy * 100, 2), "%"))

# display comparison
print(comparison)

```



```{r}
# train a decision tree model
tree_model <- rpart(Attack.Type ~ ., data = full_data, method = "class")

# make predictions
predictions <- predict(tree_model, train_features, type = "class")

# compare predictions with actual values
comparison <- data.frame(Actual = target_variable, Predicted = predictions)

# calculate accuracy
accuracy <- sum(comparison$Actual == comparison$Predicted) / nrow(comparison)
print(paste("Accuracy:", round(accuracy * 100, 2), "%"))

# display comparison
print(comparison)

```



```{r}
# train a random forest model
rf_model <- randomForest(Attack.Type ~ ., data = train_data)

# make predictions
predictions <- predict(rf_model, test_data)


target_variable1 <- test_data$Attack.Type;

# compare predictions with actual values
comparison <- data.frame(Actual = target_variable1, Predicted = predictions)

# calculate accuracy
accuracy <- sum(comparison$Actual == comparison$Predicted) / nrow(comparison)
print(paste("Accuracy:", round(accuracy * 100, 2), "%"))

# display comparison
print(comparison)
```

```{r}
# train a Naive Bayes model
nb_model <- naiveBayes(Attack.Type ~ ., data = full_data)

# make predictions
predictions <- predict(nb_model, train_features)

# compare predictions with actual values
comparison <- data.frame(Actual = target_variable, Predicted = predictions)

# calculate accuracy
accuracy <- sum(comparison$Actual == comparison$Predicted) / nrow(comparison)
print(paste("Accuracy:", round(accuracy * 100, 2), "%"))

# display comparison
print(comparison)

```


```{r}


# train a SVM model
svm_model <- svm(Attack.Type ~ ., data = full_data)

# make predictions
predictions <- predict(svm_model, train_features)

# compare predictions with actual values
comparison <- data.frame(Actual = target_variable, Predicted = predictions)

# calculate accuracy
accuracy <- sum(comparison$Actual == comparison$Predicted) / nrow(comparison)
print(paste("Accuracy:", round(accuracy * 100, 2), "%"))

# display comparison
print(comparison)



```


```{r}
# train a logistic regression model
logit_model <- multinom(Attack.Type ~ ., data = full_data)

# make predictions
predictions <- predict(logit_model, train_features)

# compare predictions with actual values
comparison <- data.frame(Actual = target_variable, Predicted = predictions)

# calculate accuracy
accuracy <- sum(comparison$Actual == comparison$Predicted) / nrow(comparison)
print(paste("Accuracy:", round(accuracy * 100, 2), "%"))

# display comparison
print(comparison)



```










